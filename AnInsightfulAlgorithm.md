# An Insightful Algorithm

Algorithm: a set of pre-set instructions to solve a problem

Deep learning: particular approach to building/training neural networks

- Target pregnancy coupons

Target used data to send coupon books for clothing/products targeted at recently pregnant women.

Man is irate that they sent it to his daughter ('Are you trying to tell my daughter to be pregnant?!') Turns out, she was and he didn't know.

Invasion of privacy. Creepy. De-anonymization. Deception. No recourse.

- Fitbit: Sex tracking

DATA PUBLIC BY DEFAULT. High-risk consequences.

When should things be opt-in vs. opt-out? Data is not just 'data' - social and personal context matter.

- Shutterfly

"We can be right sometimes, but we can also be really, horribly, tragically wrong."

- Google AdWords

Black names were 25% more likely to return ads for arrest records.

- Facebook

-# Year in Review

Inadvertent algorithmic cruelty: result of code that works in overwhelming majority of cases, but doesn't take other use cases into account. Can marginalize people in a really vulnerable position.

Increase awareness and considerations of failure modes, worst case scenarios.

-# Emotional contagion study

Can we make people a little happier, or a little sadder?
Making a depressed person, a little sadder, could be dangerous; potentially life-threatening. No opt-in/out and no transperancy.

- Affirm credit score

Based on name, email, mobile phone #, birthday and last 4 digits of SSN, and behavioral factors. Using this info, they look up info on social networks, public records, etc. to try to predict credit score.

Are these factors fair & reasonable? An inherent bias is inserted simply by what is available online (e.g. someone with a GitHub account has a privilege that not everyone can reach).

- Uber "God View"

De-anonymization. Regularly trotted out at launch parties.


While data can be used abusively, if we use it thoughtfully and apply it to social problems it can be incredibly powerful tool.

## Flipping the Paradigm
- Avoid doing hard to others.
- Consider a decisions' potential impact on others
	- Project the likelihood of consequences on *others*
- Contribute to human well-being
	- minimizing negative consequences
- Be honest and trustworthy
	- full disclosure of limitations
	- options
- Actively counter bias and inequality
	- Culture, systems, assumptions, ignorance, malice

How to draw better insights:
- Algorithmic transperancy 
	-Deep learning doesn't have an algorithm to look at: "we need other ways to provide surrogate transperancy"
- Data transperancy
- Auditing
- Accountability

## Affirmative Consent-Driven Cycle

Cycle: Ideation, research, development, release. Driven cycle.

Consent-driven: Permissional freely granted with clear appreciation 7 understanding (ahead of time) of the facts, implications, etc.
- Voluntary
- Disclosure
- Capable of good judgement
- Alternatives to choose from
- No is default. Has no risks.

Affirmative: Excluding all but the empathic 'yes!!!'

Say no to reading code that casually treats other people's life with no meaning that has no consequences.

